{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavinbajaj/bhavin15/blob/main/code_for_SAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcn8E7OAKSsC",
        "outputId": "9563dd5b-5767-4bd0-bcf1-8f2c4fa5952e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART1:QUESTION TO EMBEDDING**"
      ],
      "metadata": {
        "id": "qCtDH84CsUK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsfRzYNR_Abl",
        "outputId": "9eb745e5-da7d-40a1-c219-d4ec90ec2245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFdcit_0Fsp0",
        "outputId": "8a2bf03e-420f-4266-958f-a29c73f13810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q_LRnCeerei"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCExmaUQA9VM",
        "outputId": "a1e1d76d-0b47-43c7-b746-a5b130bc0724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "mAgVGJwcBOHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dksA3CC0C3FZ"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin'            # Path where the model is stored\n",
        "model_w2v = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)            # Loading the model using gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRCcur7DCmjn",
        "outputId": "57db816f-29ca-4907-e123-569395cac692"
      },
      "source": [
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "import copy\n",
        "from random import shuffle, seed\n",
        "import sys\n",
        "import os.path\n",
        "import argparse\n",
        "import glob\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pdb\n",
        "import string\n",
        "import h5py\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "import json\n",
        "import re\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import h5py\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Define the extract_feat function\n",
        "def extract_feat(doc):\n",
        "    '''\n",
        "    Input: A sentence\n",
        "    Output: Word Embedding of the sentence\n",
        "\n",
        "\n",
        "    '''\n",
        "    feat = []\n",
        "    for word in doc:\n",
        "        try:\n",
        "            feat.append(model_w2v[word])\n",
        "        except:\n",
        "            pass\n",
        "    return feat\n",
        "\n",
        "# Define the tokenize function\n",
        "def tokenize(sentence):\n",
        "    ''' Perform Tokenization '''\n",
        "    return [i for i in re.split(r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\", sentence) if i != '' and i != ' ' and i != '\\n']\n",
        "\n",
        "# Define the prepro_question function\n",
        "def prepro_question(imgs, method):\n",
        "    # preprocess all the questions\n",
        "    print('example processed tokens:')\n",
        "    '''\n",
        "    Input: The question from trainset.json\n",
        "    Performs tokenization and lowering of the question\n",
        "    Output: Embedded version of the question\n",
        "\n",
        "\n",
        "    '''\n",
        "    for i, img in enumerate(imgs):\n",
        "        s = img['question'].lower()\n",
        "        if method == 'nltk':\n",
        "            txt = word_tokenize(str(s).lower())\n",
        "        else:\n",
        "            txt = tokenize(s)\n",
        "        img['processed_tokens'] = txt\n",
        "        if i < 10:\n",
        "            print(txt)\n",
        "        if i % 1000 == 0:\n",
        "            sys.stdout.write(\"processing %d/%d (%.2f%% done)   \\r\" % (i, len(img), i * 100.0 / len(imgs)))\n",
        "            sys.stdout.flush()\n",
        "    return imgs\n",
        "\n",
        "# Define the get_top_answers function\n",
        "def get_top_answers(imgs, num_ans):\n",
        "    \"\"\"\n",
        "    Print the questions and returns the time, one answer is repeated\n",
        "    \"\"\"\n",
        "    counts = {}\n",
        "    for img in imgs:\n",
        "        try:\n",
        "            ans = img['answer'].lower()  # If the string is a number, it would result into error\n",
        "        except:\n",
        "            ans = str(img['answer'])\n",
        "        counts[ans] = counts.get(ans, 0) + 1\n",
        "\n",
        "    cw = sorted([(count, w) for w, count in counts.items()], reverse=True)\n",
        "    print('top answer and their counts:')\n",
        "    print('\\n'.join(map(str, cw[:20])))\n",
        "\n",
        "    vocab = []\n",
        "    for i in range(min(num_ans, len(cw))):\n",
        "        vocab.append(cw[i][1])\n",
        "\n",
        "    return vocab[:num_ans]\n",
        "\n",
        "# Define the filter_question function\n",
        "def filter_question(imgs, atoi):\n",
        "\n",
        "    new_imgs = []\n",
        "    for i, img in enumerate(imgs):\n",
        "        new_imgs.append(img)\n",
        "\n",
        "    print('question number reduce from %d to %d ' % (len(imgs), len(new_imgs)))\n",
        "    return new_imgs\n",
        "\n",
        "# Define manualMap and load data\n",
        "manualMap = {'none': '0', 'zero': '0', 'one': '1', 'two': '2', 'three':\n",
        "             '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7',\n",
        "             'eight': '8', 'nine': '9', 'ten': '10'}\n",
        "\n",
        "imgs_train = json.load(open('/content/drive/MyDrive/trainset.json', 'r'))\n",
        "num_ans = 1000\n",
        "top_ans = get_top_answers(imgs_train, num_ans)\n",
        "atoi = {w: i for i, w in enumerate(top_ans)}  # Word: Count\n",
        "itoa = {i: w for i, w in enumerate(top_ans)}  # Count: Word\n",
        "feat_dim = 300  # 300 Dimensional Vector\n",
        "imgs_data_train = json.load(open('/content/drive/MyDrive/trainset.json', 'r'))\n",
        "num_ans = 10  # Even 1 should work fine, but I had taken reference from COCO dataset, and hence, 10 (10 represents the top 10 answers to a picture)\n",
        "method = 'nltk'\n",
        "max_length = 21  # Max Length of the question\n",
        "dir_path = \"/content/drive/MyDrive/QA\"  # The path where we will be storing .h5 file\n",
        "N = 700\n",
        "\n",
        "image_path = '/content/drive/MyDrive/VQA_RAD Image Folder.zip'\n",
        "\n",
        "def save_data():\n",
        "    for i, img in enumerate(imgs_data_train[:N]):\n",
        "        img_path = image_path + img['image_name']\n",
        "\n",
        "        s = img['question']\n",
        "        print(i, s)  # Print the number and the question\n",
        "        if method == 'nltk':\n",
        "            try:\n",
        "                txt = word_tokenize(str(s).lower())\n",
        "            except:\n",
        "                txt = str(s)\n",
        "        else:\n",
        "            txt = tokenize(s)\n",
        "\n",
        "        img['processed_tokens'] = txt\n",
        "        question_id = img['qid']\n",
        "        feat = np.array(extract_feat(img['processed_tokens']))\n",
        "        label_arrays = np.zeros((1, max_length, feat_dim), dtype='float32')\n",
        "        label_length = min(max_length, len(feat))  # record the length of this sequence\n",
        "        label_arrays[0, :label_length, :300] = feat\n",
        "        try:\n",
        "            ans_arrays = atoi[img['answer'].lower()]\n",
        "        except:\n",
        "            ans_arrays = atoi[str(img['answer'])]\n",
        "\n",
        "        f = h5py.File(os.path.join(dir_path, str(question_id) + '.h5'), \"w\")\n",
        "        f.create_dataset(\"ques_train\", dtype='float32', data=label_arrays)\n",
        "        f.create_dataset(\"answers\", dtype='uint32', data=ans_arrays)\n",
        "        f.close()\n",
        "    return\n",
        "\n",
        "data = save_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMS4lzZ6Fbie",
        "outputId": "75c469d2-c45e-4779-d9cf-7078e56d0ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top answer and their counts:\n",
            "(884, 'no')\n",
            "(829, 'yes')\n",
            "(35, 'right')\n",
            "(31, 'axial')\n",
            "(23, 'left')\n",
            "(15, 'fat')\n",
            "(14, 'pa')\n",
            "(12, 'right lung')\n",
            "(12, 'pancreas')\n",
            "(12, 'one')\n",
            "(11, 'left kidney')\n",
            "(11, 'diffuse')\n",
            "(10, 'right upper lobe')\n",
            "(10, 'right sided pleural effusion')\n",
            "(10, 'right side')\n",
            "(10, 'ct')\n",
            "(10, 'brain')\n",
            "(9, 'lateral ventricles')\n",
            "(9, 'bilateral')\n",
            "(8, 'subarachnoid')\n",
            "0 Are regions of the brain infarcted?\n",
            "1 Are the lungs normal appearing?\n",
            "2 Is there evidence of a pneumothorax\n",
            "3 What type of imaging does this not represent?\n",
            "4 Is this a MRI of the chest?\n",
            "5 What is not pictured in this image?\n",
            "6 Is the trachea midline?\n",
            "7 Is there evidence of an aortic aneurysm?\n",
            "8 Where is the abnormality?\n",
            "9 Is there blunting of the costovertebral angles?\n",
            "10 Which organ system is abnormal in this image?\n",
            "11 Where is the pathology in this image?\n",
            "12 Is there a pneumothorax?\n",
            "13 What type of imaging is this?\n",
            "14 What organ system is pictured?\n",
            "15 Is there a fracture?\n",
            "16 Is there swelling of the grey matter?\n",
            "17 Is this an anterior posterior image?\n",
            "18 Is this the brain?\n",
            "19 Is there air under the diaphragm?\n",
            "20 What type of image is this?\n",
            "21 Is this a CT image?\n",
            "22 Is this an anterior-posterior image\n",
            "23 In what plane is this image oriented?\n",
            "24 Is there a skull fracture pictured?\n",
            "25 Are there >12 of ribs? \n",
            "26 Is/Are the lungs normal size?\n",
            "27 Is/Are there a rib fracture?\n",
            "28 Is/Are there fracturing in the patient's ribs?\n",
            "29 Is/Are the lung parenchyma abnormal?\n",
            "30 Is/Are the lung parenchyma abnormal?\n",
            "31 was the arterial contrast phase selected?\n",
            "32 does this plane of section include the gastric cardia?\n",
            "33 Is/Are there thickening in the patient's small bowel wall?\n",
            "34 was this taken with good x ray penetration\n",
            "35 Are the common ileac arteries and veins patent in this section?\n",
            "36 Is/Are there patency in the patient's common iliac arteries and veins?\n",
            "37 Are the common iliac vasculature open?\n",
            "38 Is/Are there patency in the patient's common iliac vasculature?\n",
            "39 Is the spleen normal size?\n",
            "40 Is/Are the spleen normal size?\n",
            "41 Is the size of the spleen normal?\n",
            "42 Is/Are the spleen normal size?\n",
            "43 Are there air fluid levels present in the small bowel?\n",
            "44 Is/Are there air fluid levels in the patient's small bowel?\n",
            "45 is there contrast material showing air-fluid levels in the small bowel\n",
            "46 Is/Are there air fluid levels in the patient's small bowel?\n",
            "47 Is/Are the mass located near/in the mid brain?\n",
            "48 Is/Are the mass located near/in the mid brain?\n",
            "49 Is the mass compressing the mid brain on this section?\n",
            "50 Is there mass compression in the patient's midbrain?\n",
            "51 Is the mass pushing on the midbrain structures?\n",
            "52 Is there mass compression in the patient's midbrain?\n",
            "53 Are brain structures shifted across the midline?\n",
            "54 Is/Are there midline shift?\n",
            "55 is there a midline shift of the cerebral parenchyma?\n",
            "56 Is/Are there midline shift?\n",
            "57 Is the gallbladder large in size?\n",
            "58 Is/Are the gallbladder large?\n",
            "59 Is the gallbladder distended?\n",
            "60 Is/Are the gallbladder distended?\n",
            "61 Are there >8 ribs shown in this image?\n",
            "62 Are there >8 of the ribs?\n",
            "63 Are there at least 8 ribs visible for good inspiratory effort?\n",
            "64 Are there at least 8 of the ribs?\n",
            "65 is this an image of the cerebellum\n",
            "66 Is this a transverse section?\n",
            "67 Is the patient's vertebral body indicative of normal aging?\n",
            "68 any observed degenerative changes in the vertebral body?\n",
            "69 Is/Are there degeneration in the patient's vertebral body?\n",
            "70 Is/Are there obstruction in the patient's small bowel?\n",
            "71 Is there evidence of herniation of the small bowel into the abdominal wall?\n",
            "72 Is/Are there herniation in the patient's small bowel through the abdominal wall?\n",
            "73 Is there evidence of an abdominal hernia?\n",
            "74 Is/Are there herniation in the patient's small bowel through the abdominal wall?\n",
            "75 Are there air-fluid levels present on this CT radiograph?\n",
            "76 Is/Are there air fluid levels in the patient's bowel?\n",
            "77 Is there evidence of air fluid levels in the patient's bowel?\n",
            "78 Is/Are there air fluid levels in the patient's bowel?\n",
            "79 Have brain structures crossed the midline of the brain?\n",
            "80 Is/Are there midline shift?\n",
            "81 Is there evidence of midlight shift of structures on this MRI?\n",
            "82 Is/Are there midline shift?\n",
            "83 was this taken in PA position?\n",
            "84 Is there evidence of air in the peritoneum?\n",
            "85 Is/Are there air in the patient's peritoneum?\n",
            "86 Is there air in the peritoneal cavity?\n",
            "87 Is/Are there air in the patient's peritoneal cavity?\n",
            "88 Are the hilar soft tissue densities symmetric?\n",
            "89 Is/Are there symmetry in the patient's hilums?\n",
            "90 Are the soft tissue densities in the left hilum equivalent in size to the soft tissue densities in the right hilum?\n",
            "91 Is/Are there equivalent size tissues densities in the patient's hilums?\n",
            "92 Is the descending aortic silhouette of normal contour?\n",
            "93 Is the descending aortic silhouette of normal contour and size?\n",
            "94 Is there tortuosity of the descending aorta?\n",
            "95 Is/Are there tortuosity in the patient's aorta?\n",
            "96 Is the descending aortic silhouette of normal size?\n",
            "97 Is/Are there tortuosity in the patient's aorta?\n",
            "98 Is the descending aortic silhouette of normal size?\n",
            "99 are the vertebral arteries patent in this section?\n",
            "100 Are the vertebral arteries patent?\n",
            "101 Are the vertebral arteries in view?\n",
            "102 Is/Are there vertebral arteries?\n",
            "103 Is/Are there hyper attenuating material in the patient's aorta?\n",
            "104 Is/Are there calcifications in the patient's aorta?\n",
            "105 Is the vertebro-basilar arterial network viewed in this section?\n",
            "106 Is/Are there vertebral/basilar artery?\n",
            "107 Is the vertebral artery/basilar artery located in this image?\n",
            "108 Is/Are there vertebral/basilar artery?\n",
            "109 Is there blurring of the grey-white matter junctions in the right temporal lobe?\n",
            "110 Is/Are there blurring of the grey-white matter in the patient's right temporal lobe?\n",
            "111 Is there no definitive border between the grey matter and white matter in the right temporal lobe?\n",
            "112 Is/Are there blurring of the grey-white matter in the patient's right temporal lobe?\n",
            "113 is there evidence of portal venous congestion?\n",
            "114 Is/Are there portal venous congestion?\n",
            "115 Is the portal vein engorged?\n",
            "116 Is/Are there portal venous congestion?\n",
            "117 is the plane of section transverse?\n",
            "118 Is the liver parenchyma normal?\n",
            "119 Is/Are the liver parenchyma normal?\n",
            "120 Is the liver parenchyma homogenous?\n",
            "121 Is/Are the liver parenchyma homogenous??\n",
            "122 Is there no evidence of any hypo- or hyperattenuations located in the liver?\n",
            "123 Is/Are the liver parenchyma homogenous??\n",
            "124 Is the liver parenchyma homogenous and normal?\n",
            "125 was this chest x ray taken in PA format?\n",
            "126 Is the stomach thickening regular and uniform or ragged/asymmetrical?\n",
            "127 How would you describe the stomach wall thickening?\n",
            "128 Is the stomach wall thickening symmetric or asymmetric?\n",
            "129 How would you describe the stomach wall thickening?\n",
            "130 Is there evidence of ectopic tissue present in surrounding organs?\n",
            "131 Is there metastatic tissue in the surrounding organs?\n",
            "132 Is there evidence of metastatic tissue on organs surrounding the liver?\n",
            "133 Is there metastatic tissue in the liver?\n",
            "134 Are lung opacities noted?\n",
            "135 Is/Are there nodules in the patient's lung?\n",
            "136 is there evidence of intraparenchymal lung nodules?\n",
            "137 Is/Are there nodules in the patient's lung?\n",
            "138 Is/Are there air in the patient's peritoneal cavity?\n",
            "139 Is/Are there air in the patient's peritoneal cavity?\n",
            "140 Is/Are the heart size normal?\n",
            "141 Is/Are the heart size normal?\n",
            "142 Are there calcifications in the cerebral arteries?\n",
            "143 Is/Are there calcifications in the patient's cerebral arteries?\n",
            "144 Is there evidence of calcifications in the cerebral arteries?\n",
            "145 Is/Are there calcifications in the patient's cerebral arteries?\n",
            "146 Is there evidence of a right apical pneumothorax on this chest x-ray?\n",
            "147 Is/Are there a pneumothorax in the patient's right lung?\n",
            "148 Is a pneumothorax present near the right lung field?\n",
            "149 Is/Are there a pneumothorax in the patient's right lung?\n",
            "150 Are the branches of the superior mesenteric arteries filled with contrast?\n",
            "151 Is/Are the superior mesenteric arteries hyperatenuated?\n",
            "152 Are the branches of the superior mesenteric arteries hyper attenuated?\n",
            "153 Is/Are the superior mesenteric arteries hyperatenuated?\n",
            "154 Is/Are the heart narrowed?\n",
            "155 Is/Are the heart narrowed?\n",
            "156 Are there any fractures in any of the ribs?\n",
            "157 Is/Are there fractures in the patient's ribs?\n",
            "158 Are any of the patient's ribs fractured?\n",
            "159 Is/Are there fractures in the patient's ribs?\n",
            "160 Is there pulmonary edema\n",
            "161 Is/Are the pulmonary vessels enlarged?\n",
            "162 Is there evidence of fluid in the peritoneal cavity?\n",
            "163 Is/Are there ascites?\n",
            "164 Is there evidence of ascites?\n",
            "165 Is/Are there ascites?\n",
            "166 Has the small bowel perforated?\n",
            "167 Is/Are there perforation in the patient's small bowel?\n",
            "168 is there evidence of pneumoperitoneum?\n",
            "169 Is this the small bowel on this image?\n",
            "170 Is/Are the cardiac contour normal?\n",
            "171 Are feces located in the colon?\n",
            "172 Is/Are there stool in the patient's colon?\n",
            "173 Is there stool in the colon?\n",
            "174 Is/Are there stool in the patient's colon?\n",
            "175 Do the left and right middle cerebral arteries appear patent on this section?\n",
            "176 Is/Are there middle cerebral arteries?\n",
            "177 Is the left and right MCA present?\n",
            "178 Is/Are there middle cerebral arteries?\n",
            "179 Is this a T2 weighted image?\n",
            "180 Is the lesion causing significant brainstem herniation?\n",
            "181 Is/Are there herniation in the patient's brainstem?\n",
            "182 Is there herniation of the brainstem secondary to the lesion\n",
            "183 Is/Are there herniation in the patient's brainstem?\n",
            "184 is it difficult to delineate the left costophrenic angle?\n",
            "185 Is/Are there blunting in the patient's left costophrenic angle?\n",
            "186 Is there blunting of the left costophrenic angle?\n",
            "187 Is/Are there blunting in the patient's left costophrenic angle?\n",
            "188 Are structures associated with the midbrain located in this image?\n",
            "189 Is/Are there midbrain structures?\n",
            "190 Is the midbrain identified in this section?\n",
            "191 Is/Are there midbrain structures?\n",
            "192 Is/Are there pneumothorax in the patient's left lung field?\n",
            "193 Is/Are there pneumothorax in the patient's left lung field?\n",
            "194 Are there more than 5 enlarged (>1 cm) lymph nodes around the stomach\n",
            "195 Are there >5 of lymph nodes near the stomach?\n",
            "196 Are there >5 lymph nodes located near the stomach?\n",
            "197 Are there >5 of lymph nodes near the stomach?\n",
            "198 Does the gallbladder appear distended?\n",
            "199 Is/Are the gallbladder enlarged?\n",
            "200 Is the gallbladder enlarged?\n",
            "201 Is/Are the gallbladder enlarged?\n",
            "202 Is this image plane taken inferior to the liver?\n",
            "203 is there any shift of midline structures visible in this section?\n",
            "204 Is/Are there midline shift?\n",
            "205 Is there shifting of structures across the middle?\n",
            "206 Is/Are there midline shift?\n",
            "207 Is/Are the right renal pelvis enlarged?\n",
            "208 Is/Are the right renal pelvis enlarged?\n",
            "209 Is there evidence of a small bowel obstruction with perforated viscus on this CT?\n",
            "210 Is there pneumonperitoneum in the small bowel?\n",
            "211 Is there evidence of a pneumoperitoneum secondary to a perforation?\n",
            "212 Is there pneumonperitoneum in the small bowel?\n",
            "213 Is there edema in the patient's right temporal lobe?\n",
            "214 Is/Are there cytotoxic edema in the patient's right temporal lobe?\n",
            "215 Is there evidence of cytotoxic edema in the right temporal lobe?\n",
            "216 Is/Are there cytotoxic edema in the patient's right temporal lobe?\n",
            "217 Does the mass have a smooth appearing border?\n",
            "218 Is/Are the mass well-defined? -yes/no\n",
            "219 Is the mass well-defined?\n",
            "220 Is/Are the mass well-defined? -yes/no\n",
            "221 Is there contrast in the colonic lumen?\n",
            "222 Is/Are there contrast in the patient's colon?\n",
            "223 Was the patient given oral contrast?\n",
            "224 Is/Are there contrast in the patient's colon?\n",
            "225 Is the celiac trunk visualized and patent?\n",
            "226 Is the celiac trunk visualized?\n",
            "227 Is/Are there visualization in the patient's celiac trunk?\n",
            "228 Is the celiac trunk patent?\n",
            "229 Is/Are there patency in the patient's celiac trunk?\n",
            "230 Is the celiac trunk able to be visualized in this patient and is it open?\n",
            "231 Is the celiac trunk able to be visualized in this patient?\n",
            "232 Is/Are there visualization in the patient's celiac trunk?\n",
            "233 Is the celiac trunk open?\n",
            "234 Is/Are there patency in the patient's celiac trunk?\n",
            "235 Is/Are there midline shift?\n",
            "236 Is/Are there midline shift?\n",
            "237 was this image taken without motion artifact\n",
            "238 was this image taken with patient in symmetrical supine position?\n",
            "239 Is/Are the left lung radioopaque?\n",
            "240 Is/Are the left lung radioopaque?\n",
            "241 Is this an image of the right and left temporal lobes?\n",
            "242 Are the liver \tsplee n\tstomac h\tand esophagus all visualized in this image?\n",
            "243 Does the GI contrast hi-light the small bowel?\n",
            "244 Is there oral contrast in the patient's small bowel?\n",
            "245 Is/Are there contrast in the patient's small bowel?\n",
            "246 Is there enlargement of the abdominal aorta on this image?\n",
            "247 Is/Are the abdominal aorta large?\n",
            "248 Is the abdominal aorta large in size?\n",
            "249 Is/Are the abdominal aorta large?\n",
            "250 Are the costophrenic angles sharp?\n",
            "251 Is/Are there no blunting in the patient's costophrenic angles?\n",
            "252 Is there no evidence of blunting of the costophrenic angles?\n",
            "253 Is/Are there no blunting in the patient's costophrenic angles?\n",
            "254 is the lung parenchyma well visualized?\n",
            "255 Has the brainstem herniated?\n",
            "256 Is/Are there herniation in the patient's brainstem?\n",
            "257 is there evidence of brainstem herniation in this section\n",
            "258 Is/Are there herniation in the patient's brainstem?\n",
            "259 are the heart and lungs displayed well in this film\n",
            "260 Is this image normal?\n",
            "261 Is this image normal?\n",
            "262 What is/are the abnormalities  near/in the lung?\n",
            "263 What is/are the abnormalities  near/in the lung?\n",
            "264 What is/are the hypointensity near/in the R hemidiaphragm?\n",
            "265 What is/are the hypointensity near/in the R hemidiaphragm?\n",
            "266 Any abnormal findings in the lower lung fields?\n",
            "267 Is/Are there abnormalities in the patient's lower lung?\n",
            "268 Are the lower lung fields normal?\n",
            "269 Is/Are there abnormalities in the patient's lower lung?\n",
            "270 Is the mass loculated?\n",
            "271 Is/Are the mass located? -yes/no\n",
            "272 Is there a loculated pancreatic mass?\n",
            "273 Is/Are the mass located? -yes/no\n",
            "274 How would you describe the abnormality?\n",
            "275 How would you describe the abnormality?\n",
            "276 What organ system is evaluated primarily?\n",
            "277 Are there gallstones?\n",
            "278 Is/Are there gallstones?\n",
            "279 Are gallstones present?\n",
            "280 Is/Are there gallstones?\n",
            "281 Is the left hemidiaphragm normal?\n",
            "282 Is this image normal?\n",
            "283 Is the left hemidiaphragm normal?\n",
            "284 Is this image normal?\n",
            "285 Is this a chest x-ray?\n",
            "286 How would you describe the lesion?\n",
            "287 What are key characteristics of the lesion?\n",
            "288 Are there abnormal findings on this image?\n",
            "289 Is/Are the brain normal?\n",
            "290 Is this brain scan normal?\n",
            "291 Is/Are the brain normal?\n",
            "292 Is the brain tissue ischemic?\n",
            "293 Is there atrophy of the brain?\n",
            "294 How would you describe the abnormality?\n",
            "295 How would you describe the abnormality?\n",
            "296 Is the abnormality focal or diffuse?\n",
            "297 What kind of scan is this?\n",
            "298 Is there evidence of calcification in the mass?\n",
            "299 Is/Are the pancreatic mass calcified? -yes/no\n",
            "300 Is the mass calcified?\n",
            "301 Is/Are the pancreatic mass calcified? -yes/no\n",
            "302 What kind of image is this?\n",
            "303 Is this a normal image?\n",
            "304 Is this image normal?\n",
            "305 Is the brain scan normal?\n",
            "306 Is this image normal?\n",
            "307 What organ is enlarged?\n",
            "308 Where is/are the abnormality located?\n",
            "309 Which organ has the abnormality?\n",
            "310 Where is/are the abnormality located?\n",
            "311 where is the cavitary lesion?\n",
            "312 Where is/are the cavitary lesion located?\n",
            "313 where is the abnormality?\n",
            "314 Where is/are the cavitary lesion located?\n",
            "315 Is the abnormality hyper dense or hypo dense?\n",
            "316 What density is the abnormality?\n",
            "317 What is/are the density of abnormality?\n",
            "318 What part of the liver is the mass located in?\n",
            "319 Where is/are the mass located?\n",
            "320 Where is the mass in the liver?\n",
            "321 Where is/are the mass located?\n",
            "322 What organ is primarily evaluated in this image?\n",
            "323 What hemisphere are the lesions located in?\n",
            "324 Where are the abnormalities?\n",
            "325 What does nodular liver suggest?\n",
            "326 What does the shape of the liver suggest?\n",
            "327 What is the brightness in the abdominal aorta?\n",
            "328 What is/are the hyperintensity near/in the aorta?\n",
            "329 What causes hyper intensity in aorta?\n",
            "330 What is/are the hyperintensity near/in the aorta?\n",
            "331 Is this a lateral film?\n",
            "332 Where in the brain is the lesion?\n",
            "333 Where is/are the mass located?\n",
            "334 Where is the lesion?\n",
            "335 Where is/are the mass located?\n",
            "336 Which organ system is imaged?\n",
            "337 Is there an abnormal lesion?\n",
            "338 Is/Are there a mass?\n",
            "339 Is there a mass?\n",
            "340 Is/Are there a mass?\n",
            "341 What does the hypodensity suggest?\n",
            "342 What caused the lesion?\n",
            "343 In what plane is this image taken?\n",
            "344 Is this a study of the chest?\n",
            "345 What is abnormal about the hila?\n",
            "346 How would you describe the hila?\n",
            "347 Is the hila normal or enlarged?\n",
            "348 What is happening in the right lung?\n",
            "349 What is/are abnormal right lung ?\n",
            "350 What is finding in the right lung?\n",
            "351 What is/are abnormal right lung ?\n",
            "352 How many spleen lesions are present/visualized in the image?\n",
            "353 What is most alarming about the appendix?\n",
            "354 Is the liver normal?\n",
            "355 Is/Are the liver normal?\n",
            "356 Is this a normal image?\n",
            "357 Is this image normal?\n",
            "358 Are the lungs normal?\n",
            "359 Is/Are the lung normal?\n",
            "360 Is the chest x-ray normal?\n",
            "361 Is this image normal?\n",
            "362 What is/are the abnormalities near/in the lung apices?\n",
            "363 What is/are the abnormalities near/in the lung apices?\n",
            "364 Where is the mass?\n",
            "365 What can cause asymmetrical breasts?\n",
            "366 Why are the breasts asymmetrical?\n",
            "367 Is the mass enhancing?\n",
            "368 Is/Are the lung normal?\n",
            "369 Is this image normal?\n",
            "370 How would you describe the abnormalities?\n",
            "371 Is/Are the lesions ring enhancing ?\n",
            "372 Where is/are the lesion located?\n",
            "373 Where is/are the abnormality located?\n",
            "374 What organ is the mass in?\n",
            "375 Where is/are the mass located?\n",
            "376 Where is the mass?\n",
            "377 Where is/are the mass located?\n",
            "378 What abnormalities are in the right upper quadrant?\n",
            "379 What is/are the abnormalities near/in the right upper quadrant?\n",
            "380 What is in the right upper quadrant?\n",
            "381 What is/are the abnormalities near/in the right upper quadrant?\n",
            "382 Which kidney is abnormal?\n",
            "383 Where is/are the abnormality located?\n",
            "384 Which kidney has abnormalities?\n",
            "385 Where is/are the abnormality located?\n",
            "386 Is there a pelvic fracture?\n",
            "387 Is this a study of the brain?\n",
            "388 What is the image suggestive of?\n",
            "389 What is the lesion most likely to be?\n",
            "390 Describe the lesions in the right kidney?\n",
            "391 How would you describe the lesion?\n",
            "392 What is seen in the right kidney?\n",
            "393 Did the patient have a cholecystectomy?\n",
            "394 Is/Are there cholescystectomy\n",
            "395 Has the gallbladder been removed?\n",
            "396 Is/Are there gallbladder removed?\n",
            "397 How would you describe the aortopulmonary window?\n",
            "398 What is/are the characteristic finding near/in the aortopulmonary window?\n",
            "399 What is/are the sign near/in the aortopulmonary window?\n",
            "400 Is there evidence of enhancement?\n",
            "401 Is/Are the lesion enhanced? -yes/no\n",
            "402 Is the lesion enhancing?\n",
            "403 Is/Are the lesion enhanced? -yes/no\n",
            "404 Is there contrast given?\n",
            "405 Is this a CT scan?\n",
            "406 Where is/are the abnormality located?\n",
            "407 Where is/are the abnormality located?\n",
            "408 Describe the appendix\n",
            "409 Are there 2 kidneys?\n",
            "410 Are there two kidneys? \n",
            "411 Are there normal number of kidneys?\n",
            "412 Are there two kidneys? \n",
            "413 Where is the mass?\n",
            "414 Where is the abnormality?\n",
            "415 Where is/are the linear hypodensity located?\n",
            "416 Where is the hypodensity located?\n",
            "417 Where is/are the linear hypodensity located?\n",
            "418 Is this image normal?\n",
            "419 Is this image normal?\n",
            "420 Which hemisphere is the ischemia located?\n",
            "421 Where is/are the abnormality located?\n",
            "422 Where is the abnormality?\n",
            "423 Where is/are the abnormality located?\n",
            "424 Is this image normal?\n",
            "425  Is/Are the right hemidiaphragm normal?\n",
            "426 Is the mass homogeneous?\n",
            "427 Where is the abnormality in this image?\n",
            "428 Where is the catheter tip located?\n",
            "429 Where is/are the catheter tip located?\n",
            "430 Where does the catheter tip extend into?\n",
            "431 Where is/are the catheter tip located?\n",
            "432 Does the mass affect neighboring structure?\n",
            "433 Is/Are there mass effect?\n",
            "434 Is there mass effect?\n",
            "435 Is/Are there mass effect?\n",
            "436 Is this image normal?\n",
            "437 Is the small bowel filled with contrast?\n",
            "438 Is the cecum dilated\n",
            "439 What does the abnormality suggest?\n",
            "440 What causes the hyperintensity?\n",
            "441 Is there fat stranding?\n",
            "442 Is the heart abnormal?\n",
            "443 Does the heart appear enlarged?\n",
            "444 Is/Are the heart enlarged? -yes/no\n",
            "445 Where is the mass?\n",
            "446 Where is/are the mass located?\n",
            "447 Where is the mass located?\n",
            "448 Where is/are the mass located?\n",
            "449 Is/Are the pancreas surrounding normal?\n",
            "450 Is/Are the pancreas surrounding normal?\n",
            "451 Which plane is the image taken?\n",
            "452 Where is this plane relative to the eyes?\n",
            "453 How was this x-ray taken?\n",
            "454 Which ribs are located near the abnormality seen in this image?\n",
            "455 What level is the abnormality located at?\n",
            "456 Is/Are there a pneumothorax present?\n",
            "457 Do the lung markings extend to the periphery?\n",
            "458 Is a pneumothorax present in this image?\n",
            "459 Does the width of the heart exceed more than half of the thorax?\n",
            "460 How wide is/are the cardiac shadow? -open\n",
            "461 How wide is the cardiac shadow?\n",
            "462 How wide is/are the cardiac shadow? -open\n",
            "463 Is the diaphragm obscured?\n",
            "464 Is/Are the diaphragm obscured?\n",
            "465 Is the diaphragm clearly visualized on both sides?\n",
            "466 Is/Are the diaphragm visualized?\n",
            "467 Are nodular calcifications present in the lungs?\n",
            "468 What lesions are present in the lungs?\n",
            "469 How big is the liver lesion?\n",
            "470 How big is/are the liver lesion? -open\n",
            "471 What is the size of the mass lesion?\n",
            "472 How big is/are the liver lesion? -open\n",
            "473 What is the modality by which the image was taken?\n",
            "474 Are the calcifications superior or inferior to the diaphragm?\n",
            "475 Where in the image are the calcifications located?\n",
            "476 Where is the aortic arch?\n",
            "477 Where is/are the aortic arch located?\n",
            "478 Which side of the image is the aortic arch visualized?\n",
            "479 Where is/are the aortic arch located?\n",
            "480 Where is the lung lesion located?\n",
            "481 Where is/are the lung lesion located?\n",
            "482 Which lobe of the lung is the lesion located in?\n",
            "483 Where is/are the lung lesion located?\n",
            "484 Do bones appear lighter on this image's modality?\n",
            "485 Are the bowel loops on the right or left side of the patient?\n",
            "486 Where in this image are the bowel loops?\n",
            "487 Is there evidence of periappendiceal fluid and fat stranding?\n",
            "488 What indicates that appendicitis is present?\n",
            "489 Is the appendix visualized with contrast?\n",
            "490 Is/Are there contrast in the patient's appendix?\n",
            "491 Is there contrast in the appendix?\n",
            "492 Is/Are there contrast in the patient's appendix?\n",
            "493 How many instances of intussusception are present/visualized in the image? - open\n",
            "494 Is/Are there more than one intussusception present?\n",
            "495 Are any organs besides the intestines present in this image?\n",
            "496 Besides the intestines, what other organs are present?\n",
            "497 Is a cystic cavity present in the left kidney on this image?\n",
            "498 Is/Are there a cystic cavity in the left kidney?\n",
            "499 Is there a cyst in the left kidney?\n",
            "500 Is/Are there a cyst in the left kidney?\n",
            "501 Is this in the lumbar vertebral level?\n",
            "502 Is the pathologic part of this image the small bowel or colon?\n",
            "503 Where is the intussesception located?\n",
            "504 Where is/are the intussesception located?\n",
            "505 How many lesions are present in the image?\n",
            "506 How many lesions are present/visualized in the image?\n",
            "507 Is there more that one lesion present?\n",
            "508 Is/Are there more than one lesion present?\n",
            "509 Is the liver normal?\n",
            "510 Is/Are the liver normal?\n",
            "511 Is a ring enhancing lesion present in the right lobe of the liver?\n",
            "512 Is/Are there ring enchancing lesion in the patient's liver?\n",
            "513 Is the lesion on the patient's right or left side?\n",
            "514 Where on the image is the lesion?\n",
            "515 What are the two major organs present in this image?\n",
            "516 Is/Are the diaphragm visualized?\n",
            "517 Is/Are the diaphragm obscured?\n",
            "518 Is the liver abnormal?\n",
            "519 Is/Are the liver abnormal?\n",
            "520 Are there any abnormal hypodense lesions in the liver?\n",
            "521  Is/Are there abnormal hypodense lesions in the patient's liver?\n",
            "522 Is/Are the heart wider than more than half the width of the thorax?\n",
            "523 How wide is/are the heart compared to the thorax? -open\n",
            "524 Is/Are the free air under the left hemidiaphragm  pathologic?\n",
            "525 Is/Are the free air under the left hemidiaphragm  pathologic?\n",
            "526 Is the largest cyst in the left or right kidney?\n",
            "527 Where is the largest cystic lesion in the image?\n",
            "528 Where is/are the largest cystic lesion located?\n",
            "529 Was oral or IV contrast used?\n",
            "530 Are the lesions in the image more or less dense than surrounding tissue?\n",
            "531 What is denser, the cystic lesions or the kidney parenchyma?\n",
            "532 Is the primary abnormality more or less dense than surrounding matter?\n",
            "533 What is denser, the mass or the surrounding brain tissue?\n",
            "534 Is the lesion in this image more or less dense than the surrounding tissue?\n",
            "535 What is denser, the lesion or the surrounding tissue?\n",
            "536 Was contrast applied?\n",
            "537 Is this an AP image?\n",
            "538 Are calcified lesions present in the lung fields?\n",
            "539 Is there evidence of large calcified lesions in the lung fields?\n",
            "540 Is/Are there calcified lesions in the patient's lung fields?\n",
            "541 Where is/are the free air located?\n",
            "542 Is/Are there free air in the patient's supraclavicular fossae?\n",
            "543 What is the organ system visualized?\n",
            "544 Is the air under the left hemidiaphragm pathologic?\n",
            "545 Is/Are the air under the left hemidiaphragm pathologic?\n",
            "546 Is there free air under the left diaphragm?\n",
            "547 Is/Are there free air in the patient's subdiaphram?\n",
            "548 Is this image of the thorax?\n",
            "549 Where is the lesion?\n",
            "550 Where is/are the lesion located?\n",
            "551 Which lung lobe is the lesion present in?\n",
            "552 Where is/are the lesion located?\n",
            "553 Where is the aneurysm located?\n",
            "554 Where is/are the aneurysm located?\n",
            "555 What is the most important abnormality found in this image?\n",
            "556 Where is/are the ascending colon located?\n",
            "557 At which rib is the lesion located?\n",
            "558 What rib is the lesion located inferior to?\n",
            "559 On which side is the cardiac border more obscured?\n",
            "560 Where is the cardiac border more obscured?\n",
            "561 What organ system is primarily present in this image?\n",
            "562 Which side of the cardiac border is more prominent?\n",
            "563 Which cardiac border is more prominently visualized?\n",
            "564 Is this image a CT scan?\n",
            "565 Is there evidence of hematoma?\n",
            "566 Is/Are there a hematoma present?\n",
            "567 Is there blood present?\n",
            "568 Is/Are there blood present?\n",
            "569 Which lung has more extensive infiltration?\n",
            "570 Where is/are the most infiltrates  located?\n",
            "571 Where are the most infiltrates located?\n",
            "572 Where is/are the most infiltrates  located?\n",
            "573 How would you describe the duodenum?\n",
            "574 How would you describe the duodenum?\n",
            "575 Is the duodenum edematous?\n",
            "576 Is the largest air collection on the patient's left or the right side?\n",
            "577 Where is the largest air collection in this image?\n",
            "578 Where is the lesion located?\n",
            "579 Where is/are the lesion located?\n",
            "580 What is the location of the primary lesion?\n",
            "581 Where is/are the lesion located?\n",
            "582 Is the air under the left hemidiaphragm pathologic?\n",
            "583 Is/Are the air under the left hemidiaphragm pathologic?\n",
            "584 Is subdiaphragmatic air present on the left side?\n",
            "585 Is/Are there subdiaphragmatic air in the patient's left side? \n",
            "586 Which side is the lateral ventricle visible on?\n",
            "587 Where is/are the lateral ventricle located?\n",
            "588 Where is the lateral ventricle?\n",
            "589 Where is/are the lateral ventricle located?\n",
            "590 Where is the lesion located?\n",
            "591 Where is/are the lesion located?\n",
            "592 Which liver lobe is the lesion in?\n",
            "593 Where is/are the lesion located?\n",
            "594 Is there an intussusception present?\n",
            "595 Is/Are there an intussusception present?\n",
            "596 Is there evidence of intussusception on the right side?\n",
            "597 Is/Are there an intussusception present?\n",
            "598 Is there a mass in the right hilum?\n",
            "599 Is/Are there a mass in the patient's right hilum?\n",
            "600 Is there evidence of a mass lesion at the right hilum?\n",
            "601 Is/Are there a mass in the patient's right hilum?\n",
            "602 Is there a fracture on the left 5th rib?\n",
            "603 Is/Are there fracture in the patient's 5th rib?\n",
            "604 Is the left fifth rib broken?\n",
            "605 Is/Are there fracture in the patient's 5th rib?\n",
            "606 Is subcutaneous air present?\n",
            "607 Is/Are there subcutaneous air present?\n",
            "608 Is there evidence of subcutaneous air collection?\n",
            "609 Is/Are there subcutaneous air present?\n",
            "610 Are any ribs in the image fractured?\n",
            "611 Is/Are there fracture in the patient's  ribs?\n",
            "612 Are there any fractures present?\n",
            "613 Is/Are there any fractures present?\n",
            "614 Where is/are the subcutaneous air collection? \n",
            "615 Is/Are there subcutaneous air present in the patient's right neck?\n",
            "616 Is the opacity near the left lung apex pathologic?\n",
            "617 Is/Are the opacity near the left lung apex pathologic?\n",
            "618 What is the opacity near the left lung apex?\n",
            "619 What is/are the opacity near/in the left lung apex? \n",
            "620 What is/are the that near/in the left apex?\n",
            "621 Is/Are there a pneumonthorax in the patient's left apex?\n",
            "622 Where is/are the lesion located?\n",
            "623 How was this image taken?\n",
            "624 Where is/are the kidneys located?\n",
            "625 Where is the lesion?\n",
            "626 Where is/are the lesion located?\n",
            "627 Which lobe is the lesion located in?\n",
            "628 Where is/are the lesion located?\n",
            "629 Is there any inappropriate air collection in subcutaneous tissue?\n",
            "630 Is/Are there subcutaneous air present?\n",
            "631 Is subcutaneous air present?\n",
            "632 Is/Are there subcutaneous air present?\n",
            "633 Where on the image is most obscured?\n",
            "634 Is the costophrenic angle blunted?\n",
            "635 Is/Are the costophrenic angle blunted? -yes/no\n",
            "636 What are the opacities to the left?\n",
            "637 Is there any hemorrhage?\n",
            "638 What are those densities in the wall of the aorta?\n",
            "639 What is the radiological description of the color of the edema?\n",
            "640 Is the cerebellum visible?\n",
            "641 Is this an axial image?\n",
            "642 Is the liver normal in size?\n",
            "643 Is this film properly exposed?\n",
            "644 Is it possible to see the cerebellum in this image?\n",
            "645 Is the heart dilated?\n",
            "646 In which lobe is the nodule located?\n",
            "647 Is the patient's kidney this large mass to the right?\n",
            "648 Are these small opacities in the right lung calcifications?\n",
            "649 Is there any shifting on the path of the trachea?\n",
            "650 Is there swelling of the choroid fissure?\n",
            "651 Is this a MRI image?\n",
            "652 Is there swelling around the lesion?\n",
            "653 What is the organ principally shown in this image?\n",
            "654 Are the basal ganglia enlarged?\n",
            "655 Is there any other alteration in the image?\n",
            "656 What are those lines in the posterior brain?\n",
            "657 Is the medulla swollen?\n",
            "658 What are these densities inside the intestines?\n",
            "659 What is the name of this image's plane?\n",
            "660 Is the lesion infiltrating?\n",
            "661 Is the abdomen distended?\n",
            "662 Is there leakage of contrast?\n",
            "663 In which lobe is the enhancement?\n",
            "664 Is this a solitary nodule?\n",
            "665 Is there ascites?\n",
            "666 Is there any hemorrhage?\n",
            "667 Is the right lung normal in size?\n",
            "668 Is there a cyst in the right kidney?\n",
            "669 What is the plane of this image?\n",
            "670 Is there involvement of the temporal lobes?\n",
            "671 Are the brain ventricles visible?\n",
            "672 Is there fluid in the anterior abdominal wall?\n",
            "673 Are the lateral ventricles compressed?\n",
            "674 Is this a cyst in the left lung?\n",
            "675 What is happening with the path of the trachea?\n",
            "676 Is the stomach dilated?\n",
            "677 Where are the enlarged feeding arteries located?\n",
            "678 Is the right kidney at its normal height in the abdomen?\n",
            "679 Is this an infiltrating mass?\n",
            "680 Is the renal mass distending the abdominal wall?\n",
            "681 Is it contrast these hyperintensities in the intestines?\n",
            "682 What is the hypodensity in the posterior left?\n",
            "683 What is this mass to the left of the patient?\n",
            "684 Is there lesion to other structures besides the medulla?\n",
            "685 What are these hyperintensities to the right?\n",
            "686 Are there any other cysts in the image?\n",
            "687 Is there any lesion in the left kidney\n",
            "688 Are there multiple masses or just a single big one?\n",
            "689 Are the kidneys atrophied?\n",
            "690 What are these hypodensities in the liver?\n",
            "691 In which lobe is the cyst?\n",
            "692 Is it possible to see the cerebellum?\n",
            "693 Is this a CT image?\n",
            "694 How do we call these wide undulations along the vertebral column?\n",
            "695 To which side is the trachea deviated?\n",
            "696 Is the left kidney affected?\n",
            "697 Is the brain atrophied or shrunk?\n",
            "698 Are there fractures on the skull?\n",
            "699 Is there any lesion to bone structures?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2:LOADING AND PREPARING THE DATASETS**"
      ],
      "metadata": {
        "id": "pmCqKVunss6v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ispHaiEEFhXy"
      },
      "source": [
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "import copy\n",
        "from random import shuffle, seed\n",
        "import sys\n",
        "import os.path\n",
        "import argparse\n",
        "import glob\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pdb\n",
        "import string\n",
        "import h5py\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "import json\n",
        "import re\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "dropout_rate = 0.4\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------\n",
        "# The below part is same as that of part 1\n",
        "\n",
        "def extract_feat(doc):\n",
        "    feat = []\n",
        "    for word in doc:\n",
        "        try:\n",
        "            feat.append(model_w2v[word])\n",
        "        except:\n",
        "            pass\n",
        "    return feat\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return [i for i in re.split(r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\", sentence) if i!='' and i!=' ' and i!='\\n'];\n",
        "\n",
        "def prepro_question(imgs, method):\n",
        "\n",
        "    # preprocess all the question\n",
        "    print('example processed tokens:')\n",
        "    for i,img in enumerate(imgs):\n",
        "        s = img['question'].lower()\n",
        "        if method == 'nltk':\n",
        "            txt = word_tokenize(str(s).lower())\n",
        "        else:\n",
        "            txt = tokenize(s)\n",
        "        img['processed_tokens'] = txt\n",
        "        if i < 10: print(txt)\n",
        "        if i % 1000 == 0:\n",
        "            sys.stdout.write(\"processing %d/%d (%.2f%% done)   \\r\" %  (i, len(img), i*100.0/len(imgs)) )\n",
        "            sys.stdout.flush()\n",
        "    return imgs\n",
        "\n",
        "def get_top_answers(imgs, num_ans):\n",
        "    counts = {}\n",
        "    for img in imgs:\n",
        "        try:\n",
        "            ans = img['answer'].lower()\n",
        "        except :\n",
        "            ans = str(img['answer'])\n",
        "        counts[ans] = counts.get(ans, 0) + 1 # Frequency count\n",
        "\n",
        "    cw = sorted([(count,w) for w,count in counts.items()], reverse=True)\n",
        "    # print('top answer and their counts:')\n",
        "    # print('\\n'.join(map(str,cw[:20])))\n",
        "\n",
        "    vocab = []\n",
        "    for i in range(min(num_ans,len(cw))):\n",
        "        vocab.append(cw[i][1])\n",
        "\n",
        "    return vocab[:num_ans]\n",
        "\n",
        "\n",
        "def filter_question(imgs, atoi):\n",
        "    new_imgs = []\n",
        "    for i, img in enumerate(imgs):\n",
        "            new_imgs.append(img)\n",
        "\n",
        "    print('question number reduce from %d to %d '%(len(imgs), len(new_imgs)))\n",
        "    return new_imgs\n",
        "# Old Part finishes\n",
        "# ---------------------------------------------------------------------------------------------------------------------\n",
        "# New part starts\n",
        "# -------------------------------------------------------------------------------------------------------------------\n",
        "def image_layer(input_shape):\n",
        "    '''\n",
        "    Input : Shape of the image\n",
        "    Output : VGG16 Preprocessing model\n",
        "    '''\n",
        "    base_model = tf.keras.applications.VGG16(input_shape=input_shape, include_top=False,weights='imagenet')\n",
        "    base_model.trainable = False # Do not train it\n",
        "    x = base_model.layers[-2].output  # Shape would be (28*28*512)\n",
        "    x = tf.reshape(x , [-1,x.shape[2]*x.shape[1] , x.shape[3]]) # Shape would be (1,784,512)\n",
        "    x = tf.keras.layers.Dense(1024)\n",
        "    return x\n",
        "\n",
        "def vgg_preprocessing(model,image):\n",
        "  ''' Takes a tensor as an input, and returns a pre processed version of the image'''\n",
        "  return model(image)\n",
        "  N=700\n",
        "\n",
        "def load_data():\n",
        "\n",
        "\n",
        "\n",
        "        images = []\n",
        "        questions = []\n",
        "        answers = []\n",
        "        ids = []\n",
        "\n",
        "        #print(start,end)\n",
        "        #arrs = np.random.randint(0,len(imgs_data_train),batch)\n",
        "        #data = [imgs_data_train[i] for i in arrs]\n",
        "\n",
        "        data = imgs_data_train[:N]   # trainset.json\n",
        "        model = image_layer(input_shape = (448,448,3)) # Making VGG16 Model\n",
        "        for i,img in enumerate(data):\n",
        "\n",
        "            img_path = img['image_name']  # Image Name\n",
        "            question_id = img['qid']      # Question id\n",
        "\n",
        "            #label_arrays = np.zeros((1, max_length, feat_dim), dtype='float32')\n",
        "\n",
        "            with h5py.File(os.path.join(dir_path,str(question_id) + '.h5'),'r') as hf:\n",
        "                question = hf['.']['ques_train'[:N]][()] # Embedded question\n",
        "                answer = hf['.']['answers'[:N]][()]    # Embedded answer\n",
        "\n",
        "            image = cv2.imread(os.path.join('/content/drive/MyDrive/VQA_RAD Image Folder',img_path) , cv2.IMREAD_COLOR) # Reading the image\n",
        "            image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image , (448,448)) # Reshape\n",
        "\n",
        "            '''\n",
        "\n",
        "            '''\n",
        "            #image = vgg_preprocessing(model,image)\n",
        "            # Apply VGG16 Preprocessings\n",
        "\n",
        "            images.append(image)\n",
        "            questions.append(np.array(question))\n",
        "            answers.append(np.array(answer))\n",
        "            ids.append(question_id)\n",
        "            if i%100==0:\n",
        "              print(\"Processed =>\",i,' which is',round(100*i/len(data),2),'%')\n",
        "\n",
        "        questions = np.reshape(np.array(questions) , [-1,max_length,feat_dim])\n",
        "        return (np.array(images) , questions ,np.array(answers) , np.array(ids))\n",
        "\n",
        "imgs_train = json.load(open('/content/drive/MyDrive/trainset.json' , 'r'))\n",
        "num_ans = 1000\n",
        "top_ans = get_top_answers(imgs_train, num_ans )\n",
        "atoi = {w:i for i,w in enumerate(top_ans)}\n",
        "itoa = {i:w for i,w in enumerate(top_ans)}\n",
        "feat_dim = 300\n",
        "imgs_data_train = json.load(open('/content/drive/MyDrive/trainset.json' , 'r'))\n",
        "num_ans = 10\n",
        "method = 'nltk'\n",
        "max_length = 21\n",
        "dir_path = \"/content/drive/MyDrive/QA\"\n",
        "N = 700\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTw0zbmjKibP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da344bf6-a1b2-4784-b439-710cd3c3c3a5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras,h5py\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import keras.activations\n",
        "import keras.backend as kbe\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.layers as layers\n",
        "from keras.layers import Activation, Add, Concatenate, Conv1D, Dense, Dropout, Embedding, Softmax\n",
        "from keras.layers import Input, GlobalMaxPooling1D, Lambda, Multiply, RepeatVector, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "import pickle\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "\n",
        "embed_size = 300\n",
        "q_len = 21\n",
        "height = 224\n",
        "width = 224\n",
        "lstm_units = 256\n",
        "attention_dim = 512\n",
        "num_output = 1000\n",
        "max_questions = 3064\n",
        "\n",
        "batch_size = 16\n",
        "lr = 0.001\n",
        "articles = ['a', 'an', 'the']\n",
        "manualMap = { 'none': '0', 'zero': '0', 'one': '1', 'two': '2', 'three':\n",
        "                  '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7',\n",
        "                  'eight': '8', 'nine': '9', 'ten': '10' }\n",
        "\n",
        "\n",
        "datagen = load_data()   # Load the Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed => 0  which is 0.0 %\n",
            "Processed => 100  which is 14.29 %\n",
            "Processed => 200  which is 28.57 %\n",
            "Processed => 300  which is 42.86 %\n",
            "Processed => 400  which is 57.14 %\n",
            "Processed => 500  which is 71.43 %\n",
            "Processed => 600  which is 85.71 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVk6XBwjnSTS"
      },
      "source": [
        "### Creating the Dataset: We do this, by renaming the contents of .h5 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFac_DuaB_1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf4f10c-18e3-45b4-d3bc-188aeb7ab162"
      },
      "source": [
        "images,questions,answers,ids =datagen[0],datagen[1],datagen[2],datagen[3]\n",
        "print(\"Images have a size of:\",images.shape)\n",
        "print(\"Questions have a size of:\",questions.shape)\n",
        "print(\"Answers have a size of:\",answers.shape)\n",
        "print(\"Ids have a size of:\",ids.shape)\n",
        "dir_path = r'/content/drive/MyDrive/QA' # The directory where the .h5 file for each entry is saved\n",
        "m = 100\n",
        "for i in range(images.shape[0]):\n",
        "    ans_array = answers[i]\n",
        "    image_array = images[i]\n",
        "    quest_array = questions[i]\n",
        "    question_id = ids[i]\n",
        "    f = h5py.File(os.path.join( dir_path , str(question_id) + '.h5'), \"w\") # Loading the 'h5 file\n",
        "    f.create_dataset(\"ques_train\", dtype='float32', data=quest_array) # Question Embedding\n",
        "    f.create_dataset(\"image_vector\", dtype='float32', data=image_array) # Image Embedding (Not preprocessed)\n",
        "    f.create_dataset(\"answers\", dtype='uint32', data=ans_array)      # Answers in embedded form\n",
        "    f.close()\n",
        "    if i%m ==0:\n",
        "        print(\"Processed =>\", i,' total percentage =>', round(100*i/images.shape[0],2),' %')\n",
        "print(\"Your processing has been done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images have a size of: (700, 448, 448, 3)\n",
            "Questions have a size of: (700, 21, 300)\n",
            "Answers have a size of: (700,)\n",
            "Ids have a size of: (700,)\n",
            "Processed => 0  total percentage => 0.0  %\n",
            "Processed => 100  total percentage => 14.29  %\n",
            "Processed => 200  total percentage => 28.57  %\n",
            "Processed => 300  total percentage => 42.86  %\n",
            "Processed => 400  total percentage => 57.14  %\n",
            "Processed => 500  total percentage => 71.43  %\n",
            "Processed => 600  total percentage => 85.71  %\n",
            "Your processing has been done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART3:MAKING THE MODEL**"
      ],
      "metadata": {
        "id": "snrvdfaItKy2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4mGx-nQBvVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc67aa5-710f-4074-fafb-b60c2bdf8ebb"
      },
      "source": [
        "# link - http://www.cs.virginia.edu/~vicente/vislang/slides/wasimonica.pdf\n",
        "import os,h5py\n",
        "# Image Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "'''  Preprocessing with the VGG 16 Model  '''\n",
        "\n",
        "model = tf.keras.applications.VGG16(include_top=False,weights='imagenet',\n",
        "        input_shape=(448,448,3))\n",
        "#print(\"The Last layer\")\n",
        "last_layer = model.layers[-1].output   # Last layer has an output layer of (14,14,512)\n",
        "model = Model(model.input,last_layer)\n",
        "model.trainable = False\n",
        "# print(model.summary())\n",
        "def extract_feature(image):\n",
        "    ''' Preprocessing with VGG Netowrk'''\n",
        "    image = model(image)\n",
        "    return image  # Shape is (196,512)\n",
        "\n",
        "'''  The below model will convert (196,512) to (21,300) (i.e same as the dimension of word embedding)  '''\n",
        "\n",
        "dimen_red = tf.keras.Sequential()  # Use for converting (196,512) -> (21,300)\n",
        "dimen_red.add(tf.keras.layers.Conv2D(300,kernel_size=(1,1),input_shape= (14,14,512)))\n",
        "dimen_red.add(tf.keras.layers.Reshape((196,300)))\n",
        "dimen_red.add(tf.keras.layers.Permute((2,1)))  # Reshaping about the axis, useful for applying the dense network\n",
        "dimen_red.add(tf.keras.layers.Dense(21))\n",
        "dimen_red.add(tf.keras.layers.Permute((2,1)))  # Reshaping about the axis, useful for applying the dense network\n",
        "\n",
        "train_dir = r'/content/drive/MyDrive/QA/' # Containing .h5 file\n",
        "images = []\n",
        "ans = []\n",
        "ques = []\n",
        "count = 0\n",
        "content = os.listdir(train_dir)[:600]   # The GPU Memory became full after this, hence had to take just these much samples :(\n",
        "length = len(content)\n",
        "for i in content:\n",
        "    # Reading the data\n",
        "    file = h5py.File(train_dir+i)\n",
        "    images.append(np.array(file['.']['image_vector'][()]))\n",
        "    ans.append(np.array(file['.']['answers'][()]))\n",
        "    ques.append(np.array(file['.']['ques_train'][()]))\n",
        "    count+=1\n",
        "    if count%100 == 0:\n",
        "      print(\"The count is:\",count,\"and the percentage proportion is:\",round(100*count/length,2),'%')\n",
        "images = tf.convert_to_tensor(np.array(images))   # For the GPU purpose\n",
        "ans = tf.convert_to_tensor(np.array(ans))\n",
        "ques = tf.convert_to_tensor(np.array(ques))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count is: 100 and the percentage proportion is: 16.67 %\n",
            "The count is: 200 and the percentage proportion is: 33.33 %\n",
            "The count is: 300 and the percentage proportion is: 50.0 %\n",
            "The count is: 400 and the percentage proportion is: 66.67 %\n",
            "The count is: 500 and the percentage proportion is: 83.33 %\n",
            "The count is: 600 and the percentage proportion is: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWOEsgqCMylS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a064924-b023-4d3e-c672-10dfbbf760c6"
      },
      "source": [
        "l = []\n",
        "length = images.shape[0]\n",
        "for i,j in enumerate(images):\n",
        "  l.append(model(tf.reshape(j,[1,448,448,3])))  # It was not possible directly on GPU, hence had to use for loop\n",
        "  if i%100 ==0:\n",
        "    print(\"The count is:\",i,\"and the percentage proportion is:\",round(100*i/length,2),'%')\n",
        "images = tf.convert_to_tensor(np.array(l) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count is: 0 and the percentage proportion is: 0.0 %\n",
            "The count is: 100 and the percentage proportion is: 16.67 %\n",
            "The count is: 200 and the percentage proportion is: 33.33 %\n",
            "The count is: 300 and the percentage proportion is: 50.0 %\n",
            "The count is: 400 and the percentage proportion is: 66.67 %\n",
            "The count is: 500 and the percentage proportion is: 83.33 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrGe6rAbSKfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf0a3a2-0091-49ed-b3b4-ffe5d6c2503b"
      },
      "source": [
        "l = []\n",
        "length = images.shape[0]\n",
        "for i,j in enumerate(images):\n",
        "  l.append(dimen_red(j))     # Making it to the same shape as that of question embedding\n",
        "  if i%100 ==0:\n",
        "    print(\"The count is:\",i,\"and the percentage proportion is:\",round(100*i/length,2),'%')\n",
        "images = tf.convert_to_tensor(np.array(l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count is: 0 and the percentage proportion is: 0.0 %\n",
            "The count is: 100 and the percentage proportion is: 16.67 %\n",
            "The count is: 200 and the percentage proportion is: 33.33 %\n",
            "The count is: 300 and the percentage proportion is: 50.0 %\n",
            "The count is: 400 and the percentage proportion is: 66.67 %\n",
            "The count is: 500 and the percentage proportion is: 83.33 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax8JyuGgWnRv"
      },
      "source": [
        "images = tf.reshape(images,[length,21,300])\n",
        "img = images  #Tensor containing images\n",
        "que = ques  # Tensor containing question vector\n",
        "img = img/255.0 # Normalizing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbFNRaVlnG9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34074731-bdc2-448d-bdb0-79d590ee9d4a"
      },
      "source": [
        "que.shape,img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([600, 21, 300]), TensorShape([600, 21, 300]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ngY_BVAxDDG"
      },
      "source": [
        "''' The below mentioned two Input objects of keras will be useful for making the model '''\n",
        "\n",
        "ques = tf.keras.layers.Input((21,300))  # Input Model (for ques)\n",
        "images = tf.keras.layers.Input((21,300)) # Input Model (for images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8VSA4N9i3Mp"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D,Flatten,Concatenate\n",
        "from keras.layers import Attention\n",
        "\n",
        "\n",
        "''' Imagica is for the preprocessing of the image part'''\n",
        "imagica = Dense(512,activation='tanh')(images)\n",
        "imagica = Dense(512,activation='tanh')(images)\n",
        "\n",
        "\n",
        "''' quesa is for the ques layer, which means preprocessing of the question layer'''\n",
        "quesa = LSTM(512, dropout = 0.3,return_sequences = True,input_shape = (21,300))(ques)\n",
        "quesa = Dense(512, activation = 'relu')(quesa)\n",
        "quesa = Dropout(0.3)(quesa)\n",
        "quesa = Dense(512, activation = 'relu')(quesa)\n",
        "quesa = Dropout(0.3)(quesa)\n",
        "\n",
        "concatenated_features = Concatenate()([imagica, quesa])\n",
        "\n",
        "# Apply attention mechanism\n",
        "attention = Attention()([concatenated_features, concatenated_features])\n",
        "\n",
        "# Combine the attention result with the concatenated features\n",
        "attended_features = Concatenate()([concatenated_features, attention])\n",
        "\n",
        "# Flatten the attended features\n",
        "attended_features = Flatten()(attended_features)\n",
        "\n",
        "# Final output layer\n",
        "out = Dense(476, activation='softmax')(attended_features)\n",
        "\n",
        "# ''' Concatenating both image and the question layer'''\n",
        "# quesa = Concatenate()([quesa,imagica])\n",
        "# quesa = Flatten()(quesa)\n",
        "# out = tf.keras.layers.Dense(476,activation='softmax')(quesa) # Final output has 476 different categories, you can check by finding length of uniquue answers :)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da6NUNV5rwR6",
        "outputId": "61f44d2b-7d99-4b7f-f2a4-9369a8d0dfda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 476) dtype=float32 (created by layer 'dense_19')>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9v_EYAWmTYNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woaDbBeRwQ8t"
      },
      "source": [
        "## Plotting the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydot graphviz\n"
      ],
      "metadata": {
        "id": "IDtaW0ywTZQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af75fc1-12f3-49c0-c2f7-e0554e634df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([ques,images],[out])"
      ],
      "metadata": {
        "id": "Cy1OdzULsAh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eVCKX_Kwdfw"
      },
      "source": [
        "## Compiling and fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG6a7918j0V-"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),loss ='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic4nCZl_3xwM",
        "outputId": "9c2a749c-3f05-4ef9-bb1f-ab51777d4f7d"
      },
      "source": [
        "answers = tf.keras.utils.to_categorical(ans)\n",
        "answers.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 455)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQnjyDfKj1dX",
        "outputId": "16d574e8-f7fa-46af-e7b2-e0141e1ef69b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 21, 300)]            0         []                            \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               (None, 21, 512)              1665024   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 21, 512)              262656    ['lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 21, 512)              0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 21, 300)]            0         []                            \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 21, 512)              262656    ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 21, 512)              154112    ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 21, 512)              0         ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 21, 1024)             0         ['dense_16[0][0]',            \n",
            " )                                                                   'dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " attention_3 (Attention)     (None, 21, 1024)             0         ['concatenate_5[0][0]',       \n",
            "                                                                     'concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 21, 2048)             0         ['concatenate_5[0][0]',       \n",
            " )                                                                   'attention_3[0][0]']         \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 43008)                0         ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 476)                  2047228   ['flatten_2[0][0]']           \n",
            "                                                          4                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22816732 (87.04 MB)\n",
            "Trainable params: 22816732 (87.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFbamvA_kJtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16253e5-d73b-479b-c473-2a50cae83793"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert your data to NumPy arrays\n",
        "img = np.array(img)\n",
        "que = np.array(que)\n",
        "ans = np.array(ans)\n",
        "\n",
        "# Split your data into training and validation sets\n",
        "img_train, img_val, que_train, que_val, ans_train, ans_val = train_test_split(img, que, ans, test_size=0.2, random_state=42)\n",
        "\n",
        "# Assuming you already have your model defined and compiled\n",
        "\n",
        "# Train the model\n",
        "model.fit([img_train, que_train], ans_train, epochs=30, batch_size=32, verbose=1, validation_data=([img_val, que_val], ans_val))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - 39s 2s/step - loss: 20.3862 - accuracy: 0.3354 - val_loss: 7.0147 - val_accuracy: 0.4500\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - 16s 963ms/step - loss: 3.7116 - accuracy: 0.6104 - val_loss: 6.1944 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - 12s 759ms/step - loss: 2.2549 - accuracy: 0.7146 - val_loss: 7.3342 - val_accuracy: 0.5250\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - 12s 796ms/step - loss: 1.9009 - accuracy: 0.8167 - val_loss: 6.6288 - val_accuracy: 0.5917\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - 12s 820ms/step - loss: 1.7293 - accuracy: 0.8208 - val_loss: 8.3138 - val_accuracy: 0.5250\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - 13s 900ms/step - loss: 1.5442 - accuracy: 0.8125 - val_loss: 6.9573 - val_accuracy: 0.5833\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - 13s 904ms/step - loss: 1.7486 - accuracy: 0.8292 - val_loss: 8.9317 - val_accuracy: 0.5667\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - 13s 859ms/step - loss: 2.3230 - accuracy: 0.8062 - val_loss: 10.5925 - val_accuracy: 0.5667\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - 15s 1s/step - loss: 2.0075 - accuracy: 0.8271 - val_loss: 12.8785 - val_accuracy: 0.4667\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - 13s 869ms/step - loss: 2.8189 - accuracy: 0.7896 - val_loss: 14.8180 - val_accuracy: 0.5500\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - 13s 876ms/step - loss: 2.7779 - accuracy: 0.8354 - val_loss: 14.2171 - val_accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - 12s 817ms/step - loss: 2.7357 - accuracy: 0.8292 - val_loss: 13.8482 - val_accuracy: 0.5417\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - 14s 891ms/step - loss: 2.7070 - accuracy: 0.8583 - val_loss: 14.8426 - val_accuracy: 0.5750\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - 11s 718ms/step - loss: 2.3628 - accuracy: 0.8646 - val_loss: 15.6144 - val_accuracy: 0.5833\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - 13s 861ms/step - loss: 2.7230 - accuracy: 0.8562 - val_loss: 14.5704 - val_accuracy: 0.5750\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - 13s 856ms/step - loss: 2.6835 - accuracy: 0.8646 - val_loss: 18.1184 - val_accuracy: 0.6000\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - 12s 838ms/step - loss: 1.8254 - accuracy: 0.8854 - val_loss: 18.8116 - val_accuracy: 0.5750\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - 12s 837ms/step - loss: 2.1924 - accuracy: 0.8750 - val_loss: 14.8612 - val_accuracy: 0.6000\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - 12s 821ms/step - loss: 2.1824 - accuracy: 0.8958 - val_loss: 13.5980 - val_accuracy: 0.6333\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - 13s 859ms/step - loss: 2.0107 - accuracy: 0.8875 - val_loss: 17.2120 - val_accuracy: 0.6000\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - 11s 721ms/step - loss: 3.3528 - accuracy: 0.8729 - val_loss: 15.9826 - val_accuracy: 0.5250\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - 12s 791ms/step - loss: 1.8871 - accuracy: 0.8792 - val_loss: 19.9789 - val_accuracy: 0.5750\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - 13s 878ms/step - loss: 3.5718 - accuracy: 0.8604 - val_loss: 18.5303 - val_accuracy: 0.6167\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - 13s 884ms/step - loss: 2.5323 - accuracy: 0.8813 - val_loss: 19.6777 - val_accuracy: 0.6000\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - 13s 883ms/step - loss: 1.9328 - accuracy: 0.9104 - val_loss: 19.5573 - val_accuracy: 0.6083\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - 13s 895ms/step - loss: 1.7839 - accuracy: 0.9271 - val_loss: 19.8718 - val_accuracy: 0.6500\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - 14s 933ms/step - loss: 1.5262 - accuracy: 0.9271 - val_loss: 19.8701 - val_accuracy: 0.6667\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - 13s 852ms/step - loss: 1.8016 - accuracy: 0.9146 - val_loss: 18.2603 - val_accuracy: 0.6333\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - 12s 816ms/step - loss: 1.5458 - accuracy: 0.9229 - val_loss: 19.2108 - val_accuracy: 0.6750\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - 12s 782ms/step - loss: 1.5083 - accuracy: 0.9229 - val_loss: 19.3680 - val_accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x781a2c8e0b80>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r5uVPs1wrTK"
      },
      "source": [
        "## Saving the Model and analysing the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBtfeMeB8Hfv"
      },
      "source": [
        "model.save('/content/drive/MyDrive/VQA_Model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLk2eZAow1rP"
      },
      "source": [
        "## END OF THE NOTEBOOK :)"
      ]
    }
  ]
}